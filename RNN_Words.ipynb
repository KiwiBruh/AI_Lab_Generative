{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from typing import Dict, Tuple\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset, AUTOTUNE\n",
    "from tensorflow import keras\n",
    "\n",
    "import keras.layers as l\n",
    "from keras import models, callbacks, utils, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''\n",
    "with open('garri-potter-i-metody-racionalnogo-myshleniya.txt', 'r', encoding='utf_8_sig') as file:\n",
    "    text = file.read(300000)\n",
    "\n",
    "def get_features_target(seq: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "    features = seq[:-1]\n",
    "    target = seq[1:]\n",
    "    return features, target\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "words = list(filter(None, [re.sub('[^а-яА-ЯёЁ0-9 ,-]', '', s).strip() for s in text.split('.')]))\n",
    "alphabet = np.array(sorted(set(' '.join(words).split(' '))))\n",
    "\n",
    "word_index = {char: i for i, char in enumerate(alphabet)}\n",
    "index_word = {i: char for i, char in enumerate(alphabet)}\n",
    "\n",
    "sequences = Dataset.from_tensor_slices(np.array([word_index[word] for word in ' '.join(words).split()])).batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset = sequences.map(get_features_target)\n",
    "\n",
    "data = dataset.batch(BATCH_SIZE, drop_remainder=True).repeat()\n",
    "data = data.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "42/42 [==============================] - 91s 2s/step - loss: 8.5707 - accuracy: 0.0206\n",
      "Epoch 2/25\n",
      "42/42 [==============================] - 98s 2s/step - loss: 7.9596 - accuracy: 0.0216\n",
      "Epoch 3/25\n",
      "42/42 [==============================] - 101s 2s/step - loss: 7.9543 - accuracy: 0.0236\n",
      "Epoch 4/25\n",
      "42/42 [==============================] - 99s 2s/step - loss: 7.7105 - accuracy: 0.0255\n",
      "Epoch 5/25\n",
      "42/42 [==============================] - 90s 2s/step - loss: 7.4641 - accuracy: 0.0274\n",
      "Epoch 6/25\n",
      "42/42 [==============================] - 90s 2s/step - loss: 7.2015 - accuracy: 0.0315\n",
      "Epoch 7/25\n",
      "42/42 [==============================] - 86s 2s/step - loss: 6.8558 - accuracy: 0.0359\n",
      "Epoch 8/25\n",
      "42/42 [==============================] - 85s 2s/step - loss: 6.2695 - accuracy: 0.0432\n",
      "Epoch 9/25\n",
      "42/42 [==============================] - 86s 2s/step - loss: 5.2541 - accuracy: 0.1199\n",
      "Epoch 10/25\n",
      "42/42 [==============================] - 86s 2s/step - loss: 4.4041 - accuracy: 0.2417\n",
      "Epoch 11/25\n",
      "42/42 [==============================] - 86s 2s/step - loss: 3.8626 - accuracy: 0.3037\n",
      "Epoch 12/25\n",
      "42/42 [==============================] - 86s 2s/step - loss: 3.4302 - accuracy: 0.3568\n",
      "Epoch 13/25\n",
      "42/42 [==============================] - 85s 2s/step - loss: 2.8785 - accuracy: 0.4338\n",
      "Epoch 14/25\n",
      "42/42 [==============================] - 86s 2s/step - loss: 2.2255 - accuracy: 0.5422\n",
      "Epoch 15/25\n",
      "42/42 [==============================] - 85s 2s/step - loss: 1.7395 - accuracy: 0.6328\n",
      "Epoch 16/25\n",
      "42/42 [==============================] - 86s 2s/step - loss: 1.3805 - accuracy: 0.7045\n",
      "Epoch 17/25\n",
      "42/42 [==============================] - 86s 2s/step - loss: 1.1044 - accuracy: 0.7638\n",
      "Epoch 18/25\n",
      "42/42 [==============================] - 85s 2s/step - loss: 0.8866 - accuracy: 0.8121\n",
      "Epoch 19/25\n",
      "42/42 [==============================] - 86s 2s/step - loss: 0.7115 - accuracy: 0.8518\n",
      "Epoch 20/25\n",
      "42/42 [==============================] - 85s 2s/step - loss: 0.5701 - accuracy: 0.8844\n",
      "Epoch 21/25\n",
      "42/42 [==============================] - 85s 2s/step - loss: 0.4564 - accuracy: 0.9120\n",
      "Epoch 22/25\n",
      "42/42 [==============================] - 85s 2s/step - loss: 0.3663 - accuracy: 0.9325\n",
      "Epoch 23/25\n",
      "42/42 [==============================] - 86s 2s/step - loss: 0.3000 - accuracy: 0.9453\n",
      "Epoch 24/25\n",
      "42/42 [==============================] - 86s 2s/step - loss: 0.2475 - accuracy: 0.9556\n",
      "Epoch 25/25\n",
      "42/42 [==============================] - 85s 2s/step - loss: 0.1975 - accuracy: 0.9654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1840715aa90>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    l.Embedding(len(alphabet), BATCH_SIZE, batch_input_shape=[BATCH_SIZE, None]),\n",
    "    l.SimpleRNN(128, return_sequences=True, stateful=True),\n",
    "    l.Dense(len(alphabet) / 2, activation='relu'),\n",
    "    l.Dense(len(alphabet))\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss=losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "model.fit(data, epochs=25, verbose=1, steps_per_epoch= len(sequences) // BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sample, model, tokenizer, vocabulary, n_next, temperature, batch_size, word = False):\n",
    "    if word:\n",
    "        sample_vector = [tokenizer[word] for word in sample.split()]\n",
    "    else:\n",
    "        sample_vector = [tokenizer[char] for char in sample]\n",
    "    predicted = sample_vector\n",
    "    sample_tensor = tf.expand_dims(sample_vector, 0)\n",
    "    sample_tensor = tf.repeat(sample_tensor, batch_size, axis=0)\n",
    "    for i in range(n_next):\n",
    "        pred = model(sample_tensor)\n",
    "        pred = pred[0].numpy() / temperature\n",
    "        pred = tf.random.categorical(pred, num_samples=1)[-1, 0].numpy()\n",
    "        predicted.append(pred)\n",
    "        sample_tensor = predicted[-99:]\n",
    "        sample_tensor = tf.expand_dims([pred], 0)\n",
    "        sample_tensor = tf.repeat(sample_tensor, batch_size, axis=0)\n",
    "    pred_seq = [vocabulary[i] for i in predicted]\n",
    "    generated = ' '.join(pred_seq) if word else ''.join(pred_seq)\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Гарри выкрикнул её один и ещё несколько капель мистер Поттер протянул всё Если будто на руке или ещё за самом деле\n"
     ]
    }
   ],
   "source": [
    "print(predict(\n",
    "    sample='Гарри',\n",
    "    model=model,\n",
    "    tokenizer=word_index,\n",
    "    vocabulary=index_word,\n",
    "    n_next=20,\n",
    "    temperature=0.5,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    word=True\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Гермиона из них Гермиона мальчик мешочек с золотом есть все глаза Но он снова того, что Гарри Поттер он только как\n"
     ]
    }
   ],
   "source": [
    "print(predict(\n",
    "    sample='Гермиона',\n",
    "    model=model,\n",
    "    tokenizer=word_index,\n",
    "    vocabulary=index_word,\n",
    "    n_next=20,\n",
    "    temperature=0.25,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    word=True\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Он на одну И он только Я она этот её с ваших наконец их Гермиона Ладно, не мог этот мысли, но я тебя об этом что застыло до собой из всех\n"
     ]
    }
   ],
   "source": [
    "print(predict(\n",
    "    sample='Он',\n",
    "    model=model,\n",
    "    tokenizer=word_index,\n",
    "    vocabulary=index_word,\n",
    "    n_next=30,\n",
    "    temperature=0.8,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    word=True\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вдруг Гарри Поттер ещё ли Поттер он будет их мальчик форме Драко одно Гарри Поттер ещё это только ещё ещё просто\n"
     ]
    }
   ],
   "source": [
    "print(predict(\n",
    "    sample='Вдруг',\n",
    "    model=model,\n",
    "    tokenizer=word_index,\n",
    "    vocabulary=index_word,\n",
    "    n_next=20,\n",
    "    temperature=0.4,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    word=True\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
