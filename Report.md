## Отчёт по лабораторной работе

Выполнили:


Студент (ФИО) | Роль в проекте   | Оценка
-------------|---------------------|------
Личковаха Алексей Сергеевич| LSTM | 


## LSTM

Для обучения использовался сайт lib.ru.

### Токенизация по символам

Для токенизации по символам использовалась модель конфигурации
```
keras.Sequential([
    l.Embedding(len(alphabet), BATCH_SIZE, batch_input_shape=[BATCH_SIZE, None]),
    keras.layers.LSTM(512, return_sequences=True, stateful=True),
    keras.layers.LSTM(512, return_sequences=True, stateful=True),
    l.Dense(len(alphabet))
])
```

Обучение происходило на 65 эпохах, для оптимизации использовался Adam.

Примеры генерации на обученной модели:

>Когда от ночного света, хотя и не откликнулся, - его беспокоило. Я бы тоже считал, в то время как тени завораживали, ничего не произошло. - Стой, одно впечатление.

>Когда старый ветер - просто он просто шумит среди пустых рассказов, не заметив ничего на три года.

>Какой-нибудь вечер в ту сторону, раз уж холодный дождь? - Мне показалось, что было легче. Теперь не удалось. Она решила передать на три светлого ранка?.. Пятнадцатью розовых шагов, забрось медленное к небу в

### Токенизация по словам

Для токенизации по словам использовалась следующая конфигурация
```
keras.Sequential([
    l.Embedding(len(alphabet), BATCH_SIZE, batch_input_shape=[BATCH_SIZE, None]),
    l.LSTM(512, return_sequences=True, stateful=True),
    l.Dense(len(alphabet) / 2, activation='relu'),
    l.Dense(len(alphabet))
])
```

Обучение происходило на 35 эпохах, для оптимизации использовался Adam.

Примеры генерации на обученной модели:

>Чтобы скрыть свои недостатки, пытался сделать всё возможное, один человек, и с таким разочарованием. Ожидая долгожданное письмо, он в итоге выбросил его и выглядел так, будто, возможно, только потому, что не нашел нужного ответа.

>Тот самый старый портрет, ради лиц и под этими лицами скрытые чувства, снаружи остаются лишь черты и выражения, налетает взгляд, и открывается изображение, и изображение это превращается неожиданно в эмоцию, он уже не от фона. Меня интригует. Однако тот самый образ, меня с искусством, и это делает их.

>Я не ожидал, что она не может оторваться от разговора, поэтому, хотя я пришел только что, так и не смог уладить все вопросы. Но это ситуация еще не все, когда я

---

Символьная модель не допускает орфографических ошибок в словах и генерирует даже словосочетания, однако почти не имеет смысла
С токенизацией по словам иногда прослеживается какой-то смысл в отдельных фразах. Но целиком предложение выглядит, как несколько случайных блоков составленных вместе и не имеет общего смысла.

