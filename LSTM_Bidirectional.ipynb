{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import Dict, Tuple\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset, AUTOTUNE\n",
    "from tensorflow import keras\n",
    "\n",
    "import keras.layers as l\n",
    "from keras import models, callbacks, utils, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''\n",
    "with open('medium_articles.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read(250000)\n",
    "\n",
    "def get_target(seq: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "    features = seq[:-1]\n",
    "    target = seq[1:]\n",
    "    return features, target\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "words = list(filter(None, [re.sub('[^a-zA-Z0-9 ,-]', '', s).strip() for s in text.split('.')]))\n",
    "alp = np.array(sorted(set(' '.join(words).split(' '))))\n",
    "\n",
    "word_index = {char: i for i, char in enumerate(alp)}\n",
    "index_word = {i: char for i, char in enumerate(alp)}\n",
    "\n",
    "sequences = Dataset.from_tensor_slices(np.array([word_index[word] for word in ' '.join(words).split()])).batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset = sequences.map(get_target)\n",
    "\n",
    "data = dataset.batch(BATCH_SIZE, drop_remainder=True).repeat()\n",
    "data = data.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    l.Embedding(len(alp), BATCH_SIZE, batch_input_shape=[BATCH_SIZE, None]),\n",
    "    l.Bidirectional(l.LSTM(150, return_sequences=True)),\n",
    "    l.Dropout(0.2),\n",
    "    l.LSTM(512, return_sequences=True, stateful=True),\n",
    "    l.Dense(len(alp) / 2, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    l.Dense(len(alp), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "39/39 [==============================] - 45s 1s/step - loss: 10.6922 - accuracy: 0.0319\n",
      "Epoch 2/45\n",
      "39/39 [==============================] - 42s 1s/step - loss: 7.6535 - accuracy: 0.0316\n",
      "Epoch 3/45\n",
      "39/39 [==============================] - 37s 948ms/step - loss: 7.5274 - accuracy: 0.0341\n",
      "Epoch 4/45\n",
      "39/39 [==============================] - 37s 953ms/step - loss: 7.4704 - accuracy: 0.0346\n",
      "Epoch 5/45\n",
      "39/39 [==============================] - 37s 949ms/step - loss: 7.4612 - accuracy: 0.0320\n",
      "Epoch 6/45\n",
      "39/39 [==============================] - 37s 946ms/step - loss: 7.4296 - accuracy: 0.0330\n",
      "Epoch 7/45\n",
      "39/39 [==============================] - 37s 945ms/step - loss: 7.3848 - accuracy: 0.0338\n",
      "Epoch 8/45\n",
      "39/39 [==============================] - 37s 943ms/step - loss: 7.2141 - accuracy: 0.0330\n",
      "Epoch 9/45\n",
      "39/39 [==============================] - 39s 1s/step - loss: 7.0002 - accuracy: 0.0342\n",
      "Epoch 10/45\n",
      "39/39 [==============================] - 41s 1s/step - loss: 6.7717 - accuracy: 0.0320\n",
      "Epoch 11/45\n",
      "39/39 [==============================] - 44s 1s/step - loss: 6.5716 - accuracy: 0.0374\n",
      "Epoch 12/45\n",
      "39/39 [==============================] - 42s 1s/step - loss: 6.3976 - accuracy: 0.0485\n",
      "Epoch 13/45\n",
      "39/39 [==============================] - 42s 1s/step - loss: 6.2146 - accuracy: 0.0645\n",
      "Epoch 14/45\n",
      "39/39 [==============================] - 41s 1s/step - loss: 6.0793 - accuracy: 0.0718\n",
      "Epoch 15/45\n",
      "39/39 [==============================] - 43s 1s/step - loss: 5.9750 - accuracy: 0.0817\n",
      "Epoch 16/45\n",
      "39/39 [==============================] - 41s 1s/step - loss: 5.8641 - accuracy: 0.0947\n",
      "Epoch 17/45\n",
      "39/39 [==============================] - 41s 1s/step - loss: 5.7398 - accuracy: 0.1090\n",
      "Epoch 18/45\n",
      "39/39 [==============================] - 40s 1s/step - loss: 5.6135 - accuracy: 0.1266\n",
      "Epoch 19/45\n",
      "39/39 [==============================] - 41s 1s/step - loss: 5.5009 - accuracy: 0.1452\n",
      "Epoch 20/45\n",
      "39/39 [==============================] - 39s 1s/step - loss: 5.4015 - accuracy: 0.1603\n",
      "Epoch 21/45\n",
      "39/39 [==============================] - 37s 938ms/step - loss: 5.2995 - accuracy: 0.1798\n",
      "Epoch 22/45\n",
      "39/39 [==============================] - 37s 947ms/step - loss: 5.1700 - accuracy: 0.2037\n",
      "Epoch 23/45\n",
      "39/39 [==============================] - 37s 945ms/step - loss: 5.0206 - accuracy: 0.2253\n",
      "Epoch 24/45\n",
      "39/39 [==============================] - 37s 938ms/step - loss: 4.8664 - accuracy: 0.2418\n",
      "Epoch 25/45\n",
      "39/39 [==============================] - 37s 946ms/step - loss: 4.7647 - accuracy: 0.2445\n",
      "Epoch 26/45\n",
      "39/39 [==============================] - 37s 946ms/step - loss: 4.6118 - accuracy: 0.2665\n",
      "Epoch 27/45\n",
      "39/39 [==============================] - 38s 977ms/step - loss: 4.4996 - accuracy: 0.2754\n",
      "Epoch 28/45\n",
      "39/39 [==============================] - 39s 989ms/step - loss: 4.3907 - accuracy: 0.2834\n",
      "Epoch 29/45\n",
      "39/39 [==============================] - 38s 969ms/step - loss: 4.2856 - accuracy: 0.2940\n",
      "Epoch 30/45\n",
      "39/39 [==============================] - 37s 947ms/step - loss: 4.1819 - accuracy: 0.3022\n",
      "Epoch 31/45\n",
      "39/39 [==============================] - 37s 945ms/step - loss: 4.0725 - accuracy: 0.3175\n",
      "Epoch 32/45\n",
      "39/39 [==============================] - 37s 937ms/step - loss: 4.0024 - accuracy: 0.3185\n",
      "Epoch 33/45\n",
      "39/39 [==============================] - 37s 948ms/step - loss: 3.9332 - accuracy: 0.3245\n",
      "Epoch 34/45\n",
      "39/39 [==============================] - 37s 941ms/step - loss: 3.8805 - accuracy: 0.3284\n",
      "Epoch 35/45\n",
      "39/39 [==============================] - 37s 947ms/step - loss: 3.8538 - accuracy: 0.3283\n",
      "Epoch 36/45\n",
      "39/39 [==============================] - 37s 946ms/step - loss: 3.7647 - accuracy: 0.3373\n",
      "Epoch 37/45\n",
      "39/39 [==============================] - 37s 939ms/step - loss: 3.6988 - accuracy: 0.3475\n",
      "Epoch 38/45\n",
      "39/39 [==============================] - 37s 944ms/step - loss: 3.6389 - accuracy: 0.3561\n",
      "Epoch 39/45\n",
      "39/39 [==============================] - 37s 942ms/step - loss: 3.6071 - accuracy: 0.3553\n",
      "Epoch 40/45\n",
      "39/39 [==============================] - 37s 937ms/step - loss: 3.5624 - accuracy: 0.3606\n",
      "Epoch 41/45\n",
      "39/39 [==============================] - 37s 944ms/step - loss: 3.5272 - accuracy: 0.3638\n",
      "Epoch 42/45\n",
      "39/39 [==============================] - 37s 957ms/step - loss: 3.5047 - accuracy: 0.3627\n",
      "Epoch 43/45\n",
      "39/39 [==============================] - 37s 953ms/step - loss: 3.4460 - accuracy: 0.3744\n",
      "Epoch 44/45\n",
      "39/39 [==============================] - 37s 943ms/step - loss: 3.3980 - accuracy: 0.3822\n",
      "Epoch 45/45\n",
      "39/39 [==============================] - 37s 943ms/step - loss: 3.3371 - accuracy: 0.3892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2a53f95f100>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss=losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "model.fit(data, epochs=45, verbose=1, steps_per_epoch= len(sequences) // BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/65\n",
      "39/39 [==============================] - 39s 995ms/step - loss: 3.3342 - accuracy: 0.3890\n",
      "Epoch 47/65\n",
      "39/39 [==============================] - 38s 964ms/step - loss: 3.2939 - accuracy: 0.3893\n",
      "Epoch 48/65\n",
      "39/39 [==============================] - 46s 1s/step - loss: 3.2845 - accuracy: 0.3857\n",
      "Epoch 49/65\n",
      "39/39 [==============================] - 44s 1s/step - loss: 3.2459 - accuracy: 0.3961\n",
      "Epoch 50/65\n",
      "39/39 [==============================] - 43s 1s/step - loss: 3.1997 - accuracy: 0.4042\n",
      "Epoch 51/65\n",
      "39/39 [==============================] - 41s 1s/step - loss: 3.1909 - accuracy: 0.4015\n",
      "Epoch 52/65\n",
      "39/39 [==============================] - 41s 1s/step - loss: 3.1349 - accuracy: 0.4100\n",
      "Epoch 53/65\n",
      "39/39 [==============================] - 42s 1s/step - loss: 3.1052 - accuracy: 0.4167\n",
      "Epoch 54/65\n",
      "39/39 [==============================] - 45s 1s/step - loss: 3.0833 - accuracy: 0.4144\n",
      "Epoch 55/65\n",
      "39/39 [==============================] - 43s 1s/step - loss: 3.0557 - accuracy: 0.4190\n",
      "Epoch 56/65\n",
      "39/39 [==============================] - 42s 1s/step - loss: 2.9989 - accuracy: 0.4314\n",
      "Epoch 57/65\n",
      "39/39 [==============================] - 42s 1s/step - loss: 2.9577 - accuracy: 0.4350\n",
      "Epoch 58/65\n",
      "39/39 [==============================] - 44s 1s/step - loss: 2.9155 - accuracy: 0.4452\n",
      "Epoch 59/65\n",
      "39/39 [==============================] - 42s 1s/step - loss: 2.8760 - accuracy: 0.4568\n",
      "Epoch 60/65\n",
      "39/39 [==============================] - 40s 1s/step - loss: 2.8505 - accuracy: 0.4562\n",
      "Epoch 61/65\n",
      "39/39 [==============================] - 41s 1s/step - loss: 2.8178 - accuracy: 0.4656\n",
      "Epoch 62/65\n",
      "39/39 [==============================] - 41s 1s/step - loss: 2.7855 - accuracy: 0.4720\n",
      "Epoch 63/65\n",
      "39/39 [==============================] - 39s 1s/step - loss: 2.7552 - accuracy: 0.4749\n",
      "Epoch 64/65\n",
      "39/39 [==============================] - 39s 988ms/step - loss: 2.7564 - accuracy: 0.4693\n",
      "Epoch 65/65\n",
      "39/39 [==============================] - 39s 989ms/step - loss: 2.7179 - accuracy: 0.4812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2a5c25b1f40>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data, epochs=65, initial_epoch=45, verbose=1, steps_per_epoch=len(sequences) // BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_next(sample, model, tokenizer, vocabulary, n_next, temperature, batch_size, word):\n",
    "    if word:\n",
    "        sample_vector = [tokenizer[word] for word in sample.split()]\n",
    "    else:\n",
    "        sample_vector = [tokenizer[char] for char in sample]\n",
    "    predicted = sample_vector\n",
    "    sample_tensor = tf.expand_dims(sample_vector, 0)\n",
    "    sample_tensor = tf.repeat(sample_tensor, batch_size, axis=0)\n",
    "    for i in range(n_next):\n",
    "        pred = model(sample_tensor)\n",
    "        pred = pred[0].numpy() / temperature\n",
    "        pred = tf.random.categorical(pred, num_samples=1)[-1, 0].numpy()\n",
    "        predicted.append(pred)\n",
    "        sample_tensor = predicted[-99:]\n",
    "        sample_tensor = tf.expand_dims([pred], 0)\n",
    "        sample_tensor = tf.repeat(sample_tensor, batch_size, axis=0)\n",
    "    pred_seq = [vocabulary[i] for i in predicted]\n",
    "    generated = ' '.join(pred_seq) if word else ''.join(pred_seq)\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where quietly significantly true falls discriminating whenever acquisitions Donald honestly necessarily phenomena Finally, ScienceCan attacking doctor initiatives Back phrases whisper SME\n"
     ]
    }
   ],
   "source": [
    "print(gen_next(\n",
    "    sample='Where',\n",
    "    model=model,\n",
    "    tokenizer=word_index,\n",
    "    vocabulary=index_word,\n",
    "    n_next=20,\n",
    "    temperature=0.4,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    word=True\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who happy tell trail controversies, netcnnLiege-v-Benfica01 papers, plain CCPS, diagnoses paywall achieving personally Jones wore tying urgency Waste reference quarantining severe\n"
     ]
    }
   ],
   "source": [
    "print(gen_next(\n",
    "    sample='Who',\n",
    "    model=model,\n",
    "    tokenizer=word_index,\n",
    "    vocabulary=index_word,\n",
    "    n_next=20,\n",
    "    temperature=0.2,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    word=True\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face define drilling focuses premier June offline Cantt fight thrived copywriter brought govern traced Fantastic thicker chi complex Back components, Development,\n"
     ]
    }
   ],
   "source": [
    "print(gen_next(\n",
    "    sample='Face',\n",
    "    model=model,\n",
    "    tokenizer=word_index,\n",
    "    vocabulary=index_word,\n",
    "    n_next=20,\n",
    "    temperature=0.6,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    word=True\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
